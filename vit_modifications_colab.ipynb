{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "20a90a41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20a90a41",
        "outputId": "837118d9-8406-4653-a8d3-e0cc0d87a181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (1.14.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets accelerate evaluate scikit-learn\n",
        "\n",
        "!pip install --upgrade sympy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "195fb972",
      "metadata": {
        "id": "195fb972"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torchvision.transforms as transforms\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    ViTImageProcessor,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "import evaluate\n",
        "import json\n",
        "import time\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fc8de737",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc8de737",
        "outputId": "a692707e-cf4b-48fb-b211-bdb20add7dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Device: cuda\n",
            "GPU: Tesla T4\n",
            "Sun Dec 14 15:26:39 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0             29W /   70W |    8480MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Create output directory\n",
        "CSV_OUTPUT_DIR = './csv_results'\n",
        "os.makedirs(CSV_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Set random seeds\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Check device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nDevice: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    !nvidia-smi\n",
        "\n",
        "\n",
        "def clear_memory():\n",
        "    \"\"\"Clear GPU/CPU memory cache\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "14e026d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14e026d5",
        "outputId": "91cea8c9-26d4-477c-a5ea-45b80649cab5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading CIFAR-10 Dataset\n",
            "\n",
            "Dataset: CIFAR-10\n",
            "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
            "Training samples: 50000\n",
            "Test samples: 10000\n"
          ]
        }
      ],
      "source": [
        "print(\"Loading CIFAR-10 Dataset\")\n",
        "\n",
        "# Load CIFAR-10\n",
        "dataset = load_dataset('cifar10')\n",
        "labels = dataset['train'].features['label'].names\n",
        "num_labels = len(labels)\n",
        "\n",
        "print(f\"\\nDataset: CIFAR-10\")\n",
        "print(f\"Classes: {labels}\")\n",
        "print(f\"Training samples: {len(dataset['train'])}\")\n",
        "print(f\"Test samples: {len(dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a01c84f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a01c84f2",
        "outputId": "f1ac775a-7708-4a0e-9102-98802f017355"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing with augmentation\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "\n",
        "# Define augmentation transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "])\n",
        "\n",
        "def preprocess_images_train(examples):\n",
        "    \"\"\"Training preprocessing with augmentation\"\"\"\n",
        "    images = []\n",
        "    for img in examples['img']:\n",
        "        img = img.convert('RGB')\n",
        "        img = train_transforms(img)\n",
        "        images.append(img)\n",
        "\n",
        "    inputs = processor(images, return_tensors='pt')\n",
        "    inputs['labels'] = examples['label']\n",
        "    return inputs\n",
        "\n",
        "def preprocess_images_val(examples):\n",
        "    \"\"\"Validation preprocessing without augmentation\"\"\"\n",
        "    images = [img.convert('RGB') for img in examples['img']]\n",
        "    inputs = processor(images, return_tensors='pt')\n",
        "    inputs['labels'] = examples['label']\n",
        "    return inputs\n",
        "\n",
        "print(\"Preprocessing with augmentation\")\n",
        "train_ds = dataset['train'].with_transform(preprocess_images_train)\n",
        "val_ds = dataset['test'].with_transform(preprocess_images_val)\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "FbcDBQBIOEhp",
      "metadata": {
        "id": "FbcDBQBIOEhp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import ViTConfig, ViTModel\n",
        "import math\n",
        "\n",
        "class LayerScale(nn.Module):\n",
        "    def __init__(self, dim, init_values=1e-5, inplace=False):\n",
        "        super().__init__()\n",
        "        self.inplace = inplace\n",
        "        self.gamma = nn.Parameter(init_values * torch.ones(dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.mul_(self.gamma) if self.inplace else x * self.gamma\n",
        "\n",
        "class SoftTargetCrossEntropy(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SoftTargetCrossEntropy, self).__init__()\n",
        "\n",
        "    def forward(self, x, target):\n",
        "        loss = torch.sum(-target * F.log_softmax(x, dim=-1), dim=-1)\n",
        "        return loss.mean()\n",
        "\n",
        "class FastWindowAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Window based local attention\n",
        "    Computes attention only within local windows for efficiency and locality bias.\n",
        "    \"\"\"\n",
        "    def __init__(self, hidden_size, num_heads=8, window_size=7, shift_size=0):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = hidden_size // num_heads\n",
        "        self.window_size = window_size\n",
        "\n",
        "        self.qkv = nn.Linear(hidden_size, hidden_size * 3, bias=True)\n",
        "        self.proj = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "\n",
        "    def window_partition(self, x, window_size):\n",
        "        B, H, W, C = x.shape\n",
        "        pad_h = (window_size - H % window_size) % window_size\n",
        "        pad_w = (window_size - W % window_size) % window_size\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            x = F.pad(x, (0, 0, 0, pad_w, 0, pad_h))\n",
        "\n",
        "        Hp, Wp = x.shape[1], x.shape[2]\n",
        "        x = x.view(B, Hp // window_size, window_size, Wp // window_size, window_size, C)\n",
        "        windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
        "        return windows, Hp, Wp\n",
        "\n",
        "    def window_reverse(self, windows, window_size, H, W, Hp, Wp):\n",
        "        B = int(windows.shape[0] / (Hp * Wp / window_size / window_size))\n",
        "        x = windows.view(B, Hp // window_size, Wp // window_size, window_size, window_size, -1)\n",
        "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, Hp, Wp, -1)\n",
        "\n",
        "        if Hp > H or Wp > W:\n",
        "            x = x[:, :H, :W, :]\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, H, W):\n",
        "        B, L, C = x.shape\n",
        "        x_2d = x.view(B, H, W, C)\n",
        "\n",
        "        windows, Hp, Wp = self.window_partition(x_2d, self.window_size)\n",
        "        windows = windows.view(-1, self.window_size * self.window_size, C)\n",
        "\n",
        "        qkv = self.qkv(windows).reshape(windows.shape[0], windows.shape[1], 3, self.num_heads, self.head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv.unbind(0)\n",
        "\n",
        "        attn_out = F.scaled_dot_product_attention(q, k, v)\n",
        "\n",
        "        attn_out = attn_out.transpose(1, 2).reshape(windows.shape[0], windows.shape[1], C)\n",
        "        x_out = self.window_reverse(attn_out, self.window_size, H, W, Hp, Wp)\n",
        "\n",
        "        x_out = x_out.reshape(B, L, C)\n",
        "\n",
        "        return self.proj(x_out)\n",
        "\n",
        "class HybridLayer(nn.Module):\n",
        "    def __init__(self, hidden_size, num_heads, window_size=7, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.local_attn = FastWindowAttention(hidden_size, num_heads, window_size=window_size)\n",
        "        self.global_attn = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout, batch_first=True)\n",
        "\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(hidden_size * 2, hidden_size),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_size)\n",
        "        self.norm2 = nn.LayerNorm(hidden_size)\n",
        "        self.ls1 = LayerScale(hidden_size)\n",
        "        self.ls2 = LayerScale(hidden_size)\n",
        "\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_size * 4, hidden_size),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        cls_token = x[:, 0:1]\n",
        "        patches = x[:, 1:]\n",
        "\n",
        "        H = W = int(math.sqrt(patches.shape[1]))\n",
        "\n",
        "        x_norm = self.norm1(x)\n",
        "        patches_norm = x_norm[:, 1:]\n",
        "\n",
        "        # local window attention\n",
        "        local_out_patches = self.local_attn(patches_norm, H, W)\n",
        "        local_out = torch.cat([torch.zeros_like(cls_token), local_out_patches], dim=1)\n",
        "\n",
        "        # global attention\n",
        "        global_out, _ = self.global_attn(x_norm, x_norm, x_norm, need_weights=False)\n",
        "\n",
        "        # gating mechanism\n",
        "        combined = torch.cat([local_out, global_out], dim=-1)\n",
        "        gate_score = self.gate(combined)\n",
        "        attn_out = gate_score * local_out + (1 - gate_score) * global_out\n",
        "\n",
        "        x = x + self.ls1(attn_out)\n",
        "        x = x + self.ls2(self.ffn(self.norm2(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "class ViTWithHybridAttention(nn.Module):\n",
        "    def __init__(self, base_model_name='google/vit-base-patch16-224', num_labels=10, num_hybrid_layers=2):\n",
        "        super().__init__()\n",
        "        self.vit = ViTModel.from_pretrained(base_model_name)\n",
        "        config = self.vit.config\n",
        "\n",
        "        self.hybrid_layers = nn.ModuleList([\n",
        "            HybridLayer(config.hidden_size, config.num_attention_heads, window_size=3, dropout=0.1)\n",
        "            for _ in range(num_hybrid_layers)\n",
        "        ])\n",
        "\n",
        "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, pixel_values, labels=None):\n",
        "        out = self.vit(pixel_values)\n",
        "        x = out.last_hidden_state\n",
        "\n",
        "        for layer in self.hybrid_layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # global average pooling\n",
        "        patch_embeddings = x[:, 1:, :]\n",
        "        global_pool = patch_embeddings.mean(dim=1)\n",
        "\n",
        "        logits = self.classifier(global_pool)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if labels.dim() > 1:\n",
        "                loss_fct = SoftTargetCrossEntropy()\n",
        "            else:\n",
        "                loss_fct = nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "\n",
        "        return {'loss': loss, 'logits': logits}\n",
        "\n",
        "def create_model(num_labels=10, num_hybrid_layers=2):\n",
        "    \"\"\"Create ViT with Hybrid Attention model\"\"\"\n",
        "    return ViTWithHybridAttention(num_labels=num_labels, num_hybrid_layers=num_hybrid_layers)\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"Count trainable and total parameters\"\"\"\n",
        "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total = sum(p.numel() for p in model.parameters())\n",
        "    return trainable, total"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "365c94ea",
      "metadata": {
        "id": "365c94ea"
      },
      "source": [
        "## 4. CutMix & MixUp Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "bfdb3719",
      "metadata": {
        "id": "bfdb3719"
      },
      "outputs": [],
      "source": [
        "class AugmentationConfig:\n",
        "    \"\"\"Config for augmentation settings\"\"\"\n",
        "    def __init__(self, use_cutmix=True, use_mixup=True,\n",
        "                 cutmix_prob=0.4, mixup_prob=0.2,\n",
        "                 cutmix_alpha=0.8, mixup_alpha=0.6):\n",
        "        self.use_cutmix = use_cutmix\n",
        "        self.use_mixup = use_mixup\n",
        "        self.cutmix_prob = cutmix_prob\n",
        "        self.mixup_prob = mixup_prob\n",
        "        self.cutmix_alpha = cutmix_alpha\n",
        "        self.mixup_alpha = mixup_alpha\n",
        "\n",
        "def rand_bbox(size, lam):\n",
        "    \"\"\"Generate random bounding box for CutMix\"\"\"\n",
        "    W, H = size[2], size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = int(W * cut_rat)\n",
        "    cut_h = int(H * cut_rat)\n",
        "\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "\n",
        "def cutmix_data(images, labels, alpha=1.0):\n",
        "    \"\"\"Apply CutMix augmentation\"\"\"\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = images.size(0)\n",
        "    index = torch.randperm(batch_size).to(images.device)\n",
        "\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(images.size(), lam)\n",
        "    images[:, :, bbx1:bbx2, bby1:bby2] = images[index, :, bbx1:bbx2, bby1:bby2]\n",
        "\n",
        "    # Adjust lambda based on actual box size\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (images.size()[-1] * images.size()[-2]))\n",
        "\n",
        "    return images, labels, labels[index], lam\n",
        "\n",
        "def mixup_data(images, labels, alpha=1.0):\n",
        "    \"\"\"Apply MixUp augmentation\"\"\"\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = images.size(0)\n",
        "    index = torch.randperm(batch_size).to(images.device)\n",
        "\n",
        "    mixed_images = lam * images + (1 - lam) * images[index]\n",
        "\n",
        "    return mixed_images, labels, labels[index], lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    \"\"\"Loss function for MixUp/CutMix\"\"\"\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
        "\n",
        "class AugmentedTrainer(Trainer):\n",
        "    \"\"\"Custom trainer with CutMix and MixUp support\"\"\"\n",
        "\n",
        "    def __init__(self, *args, aug_config=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.aug_config = aug_config or AugmentationConfig()\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
        "        \"\"\"Custom loss with MixUp/CutMix - memory optimized\"\"\"\n",
        "        inputs = dict(inputs)\n",
        "\n",
        "        labels = inputs.pop(\"labels\")\n",
        "\n",
        "\n",
        "        if self.model.training:\n",
        "            r = np.random.rand()\n",
        "\n",
        "            if self.aug_config.use_cutmix and r < self.aug_config.cutmix_prob:\n",
        "                # CutMix\n",
        "                inputs['pixel_values'], labels_a, labels_b, lam = cutmix_data(\n",
        "                    inputs['pixel_values'], labels, self.aug_config.cutmix_alpha\n",
        "                )\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "                logits = outputs['logits'] if isinstance(outputs, dict) else outputs.logits\n",
        "\n",
        "                loss = lam * nn.functional.cross_entropy(logits, labels_a) + \\\n",
        "                       (1 - lam) * nn.functional.cross_entropy(logits, labels_b)\n",
        "\n",
        "                # free memory\n",
        "                del labels_a, labels_b\n",
        "\n",
        "            elif self.aug_config.use_mixup and r < (self.aug_config.cutmix_prob + self.aug_config.mixup_prob):\n",
        "                # MixUp\n",
        "                inputs['pixel_values'], labels_a, labels_b, lam = mixup_data(\n",
        "                    inputs['pixel_values'], labels, self.aug_config.mixup_alpha\n",
        "                )\n",
        "                outputs = model(**inputs)\n",
        "\n",
        "                logits = outputs['logits'] if isinstance(outputs, dict) else outputs.logits\n",
        "\n",
        "                loss = lam * nn.functional.cross_entropy(logits, labels_a) + \\\n",
        "                       (1 - lam) * nn.functional.cross_entropy(logits, labels_b)\n",
        "\n",
        "                # Free memory\n",
        "                del labels_a, labels_b\n",
        "\n",
        "            else:\n",
        "                # Normal training\n",
        "                outputs = model(**inputs, labels=labels)\n",
        "\n",
        "                loss = outputs['loss'] if isinstance(outputs, dict) else outputs.loss\n",
        "        else:\n",
        "            # Validation\n",
        "            outputs = model(**inputs, labels=labels)\n",
        "            loss = outputs['loss'] if isinstance(outputs, dict) else outputs.loss\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
        "          inputs = self._prepare_inputs(inputs)\n",
        "\n",
        "          labels = None\n",
        "          if self.label_names:\n",
        "              labels = tuple(inputs.get(name).detach() for name in self.label_names if inputs.get(name) is not None)\n",
        "              if len(labels) == 1:\n",
        "                  labels = labels[0]\n",
        "              elif len(labels) == 0:\n",
        "                  labels = None\n",
        "\n",
        "          has_labels = labels is not None\n",
        "\n",
        "          with torch.no_grad():\n",
        "              if has_labels:\n",
        "                  loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
        "                  loss = loss.detach()\n",
        "                  if isinstance(outputs, dict):\n",
        "                      logits = outputs.get('logits')\n",
        "                      if logits is not None:\n",
        "                          logits = logits.detach()\n",
        "                  else:\n",
        "                      logits = outputs.logits.detach()\n",
        "              else:\n",
        "                  loss = None\n",
        "                  outputs = model(**inputs)\n",
        "                  if isinstance(outputs, dict):\n",
        "                      logits = outputs.get('logits')\n",
        "                      if logits is not None:\n",
        "                          logits = logits.detach()\n",
        "                  else:\n",
        "                      logits = outputs.logits.detach()\n",
        "\n",
        "          if prediction_loss_only:\n",
        "              return (loss, None, None)\n",
        "\n",
        "          return (loss, logits, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "911a3979",
      "metadata": {
        "id": "911a3979"
      },
      "source": [
        "## 5. Experiment Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e8d2ecfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8d2ecfe",
        "outputId": "e3f92fe0-7ecc-4f61-8b2f-2640dff59903"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configured experiment: hybrid_attention\n",
            "Description: ViT with Local + Global Attention (3 layers, window=3)\n"
          ]
        }
      ],
      "source": [
        "EXPERIMENT_CONFIG = {\n",
        "    'name': 'hybrid_attention',\n",
        "    'num_hybrid_layers': 3,\n",
        "    'description': 'ViT with Local + Global Attention (3 layers, window=3)',\n",
        "    'learning_rate': 5e-5,\n",
        "    'batch_size': 64,\n",
        "    'num_epochs': 50,\n",
        "    'weight_decay': 0.05,\n",
        "    'warmup_ratio': 0.1,\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'aug_config': AugmentationConfig(\n",
        "        use_cutmix=True,\n",
        "        use_mixup=True,\n",
        "        cutmix_prob=0.4,\n",
        "        mixup_prob=0.2,\n",
        "        cutmix_alpha=0.8,\n",
        "        mixup_alpha=0.6\n",
        "    )\n",
        "}\n",
        "\n",
        "print(f\"Configured experiment: {EXPERIMENT_CONFIG['name']}\")\n",
        "print(f\"Description: {EXPERIMENT_CONFIG['description']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5062cd12",
      "metadata": {
        "id": "5062cd12"
      },
      "source": [
        "## 6. Metrics & Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5652ef20",
      "metadata": {
        "id": "5652ef20"
      },
      "outputs": [],
      "source": [
        "accuracy_metric = evaluate.load('accuracy')\n",
        "f1_metric = evaluate.load('f1')\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics during training/evaluation - memory optimized\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.detach().cpu().numpy()\n",
        "    if isinstance(labels, torch.Tensor):\n",
        "        labels = labels.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1_macro = f1_metric.compute(predictions=predictions, references=labels, average='macro')\n",
        "    f1_weighted = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
        "\n",
        "    precision_macro, recall_macro, _, _ = precision_recall_fscore_support(\n",
        "        labels, predictions, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    # Clear memory\n",
        "    del predictions, labels\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy['accuracy'],\n",
        "        'f1_macro': f1_macro['f1'],\n",
        "        'f1_weighted': f1_weighted['f1'],\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "be86d862",
      "metadata": {
        "id": "be86d862"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_detailed(trainer, dataset, config_name):\n",
        "    \"\"\"Generate comprehensive evaluation metrics and visualizations\"\"\"\n",
        "    print(f\"Evaluation: {config_name.upper()}\")\n",
        "\n",
        "    predictions = trainer.predict(dataset)\n",
        "    preds = np.argmax(predictions.predictions, axis=1)\n",
        "    true_labels = predictions.label_ids\n",
        "\n",
        "    # Classification report\n",
        "    print(\"Classification report\")\n",
        "    report = classification_report(true_labels, preds, target_names=labels, digits=4, output_dict=True)\n",
        "    print(classification_report(true_labels, preds, target_names=labels, digits=4))\n",
        "\n",
        "    report_df = pd.DataFrame(report).transpose()\n",
        "    report_csv_path = os.path.join(CSV_OUTPUT_DIR, f'{config_name}_classification_report.csv')\n",
        "    report_df.to_csv(report_csv_path)\n",
        "    print(f\"Saved to: {report_csv_path}\")\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(true_labels, preds)\n",
        "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "    cm_csv_path = os.path.join(CSV_OUTPUT_DIR, f'{config_name}_confusion_matrix.csv')\n",
        "    cm_df.to_csv(cm_csv_path)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=labels, yticklabels=labels, cbar_kws={'label': 'Count'})\n",
        "    plt.title(f'Confusion Matrix - {config_name.replace(\"_\", \" \").title()}',\n",
        "              fontsize=16, fontweight='bold')\n",
        "    plt.ylabel('True Label', fontsize=12)\n",
        "    plt.xlabel('Predicted Label', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'confusion_matrix_{config_name}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    # Per-class metrics\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        true_labels, preds, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    per_class_df = pd.DataFrame({\n",
        "        'Class': labels,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'Support': support\n",
        "    })\n",
        "    per_class_csv_path = os.path.join(CSV_OUTPUT_DIR, f'{config_name}_per_class_metrics.csv')\n",
        "    per_class_df.to_csv(per_class_csv_path, index=False)\n",
        "\n",
        "    # Overall metrics\n",
        "    accuracy = accuracy_score(true_labels, preds)\n",
        "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "        true_labels, preds, average='macro', zero_division=0\n",
        "    )\n",
        "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
        "        true_labels, preds, average='weighted', zero_division=0\n",
        "    )\n",
        "\n",
        "    print(\"All Metrics:\")\n",
        "    print(f\"Accuracy:            {accuracy:.4f}\")\n",
        "    print(f\"Precision (Macro):   {precision_macro:.4f}\")\n",
        "    print(f\"Recall (Macro):      {recall_macro:.4f}\")\n",
        "    print(f\"F1-Score (Macro):    {f1_macro:.4f}\")\n",
        "    print(f\"F1-Score (Weighted): {f1_weighted:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'config_name': config_name,\n",
        "        'accuracy': accuracy,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'f1_macro': f1_macro,\n",
        "        'precision_weighted': precision_weighted,\n",
        "        'recall_weighted': recall_weighted,\n",
        "        'f1_weighted': f1_weighted,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2cf48cbe",
      "metadata": {
        "id": "2cf48cbe"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(log_history, config_name):\n",
        "    \"\"\"Plot training curves\"\"\"\n",
        "    train_loss, eval_loss, eval_accuracy = [], [], []\n",
        "    steps, eval_steps, epochs = [], [], []\n",
        "\n",
        "    for entry in log_history:\n",
        "        if 'loss' in entry and 'step' in entry:\n",
        "            train_loss.append(entry['loss'])\n",
        "            steps.append(entry['step'])\n",
        "        if 'eval_loss' in entry and 'step' in entry:\n",
        "            eval_loss.append(entry['eval_loss'])\n",
        "            eval_accuracy.append(entry.get('eval_accuracy', 0))\n",
        "            eval_steps.append(entry['step'])\n",
        "            epochs.append(entry.get('epoch', 0))\n",
        "\n",
        "    if not train_loss:\n",
        "        print(\"Warning: No training history to plot\")\n",
        "        return\n",
        "\n",
        "    training_history_df = pd.DataFrame({'step': steps, 'train_loss': train_loss})\n",
        "    eval_history_df = pd.DataFrame({\n",
        "        'step': eval_steps, 'epoch': epochs,\n",
        "        'eval_loss': eval_loss, 'eval_accuracy': eval_accuracy\n",
        "    })\n",
        "\n",
        "    training_history_df.to_csv(os.path.join(CSV_OUTPUT_DIR, f'{config_name}_training_history.csv'), index=False)\n",
        "    eval_history_df.to_csv(os.path.join(CSV_OUTPUT_DIR, f'{config_name}_eval_history.csv'), index=False)\n",
        "\n",
        "    # Plot\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "    ax1.plot(steps, train_loss, label='Training Loss', linewidth=2, color='#2E86DE')\n",
        "    if eval_loss:\n",
        "        ax1.plot(eval_steps, eval_loss, label='Validation Loss',\n",
        "                linewidth=2.5, marker='o', markersize=6, color='#EE5A6F')\n",
        "    ax1.set_xlabel('Training Steps', fontsize=11)\n",
        "    ax1.set_ylabel('Loss', fontsize=11)\n",
        "    ax1.set_title(f'Loss Curves - {config_name.replace(\"_\", \" \").title()}',\n",
        "                  fontsize=13, fontweight='bold')\n",
        "    ax1.legend(fontsize=10)\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    if eval_accuracy:\n",
        "        ax2.plot(eval_steps, eval_accuracy, label='Validation Accuracy',\n",
        "                linewidth=2.5, marker='o', markersize=6, color='#26DE81')\n",
        "        ax2.set_xlabel('Training Steps', fontsize=11)\n",
        "        ax2.set_ylabel('Accuracy', fontsize=11)\n",
        "        ax2.set_title(f'Validation Accuracy - {config_name.replace(\"_\", \" \").title()}',\n",
        "                      fontsize=13, fontweight='bold')\n",
        "        ax2.legend(fontsize=10)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.set_ylim([0, 1.0])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'training_history_{config_name}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3ee15b8",
      "metadata": {
        "id": "d3ee15b8"
      },
      "source": [
        "## 7. Training Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "aedca560",
      "metadata": {
        "id": "aedca560"
      },
      "outputs": [],
      "source": [
        "def train_hybrid_attention(config):\n",
        "    \"\"\"Train ViT with Hybrid Attention\"\"\"\n",
        "    config_name = config['name']\n",
        "\n",
        "    print(f\"Experiments: {config_name.upper()}\")\n",
        "    print(f\"\\nDescription: {config['description']}\")\n",
        "    print(f\"Learning Rate: {config['learning_rate']}\")\n",
        "    print(f\"Batch Size: {config['batch_size']}\")\n",
        "    print(f\"Gradient Accumulation: {config['gradient_accumulation_steps']}\")\n",
        "    print(f\"Effective Batch: {config['batch_size'] * config['gradient_accumulation_steps']}\")\n",
        "    print(f\"Epochs: {config['num_epochs']}\")\n",
        "    print(f\"Weight Decay: {config['weight_decay']}\")\n",
        "    print(f\"Warmup Ratio: {config['warmup_ratio']}\")\n",
        "\n",
        "    aug_cfg = config['aug_config']\n",
        "    print(f\"\\nAugmentation Settings:\")\n",
        "    print(f\"\\tBasic Augmentation: Enabled (flip, rotation, color jitter)\")\n",
        "    print(f\"\\tCutMix: {aug_cfg.use_cutmix} (prob={aug_cfg.cutmix_prob}, alpha={aug_cfg.cutmix_alpha})\")\n",
        "    print(f\"\\tMixUp: {aug_cfg.use_mixup} (prob={aug_cfg.mixup_prob}, alpha={aug_cfg.mixup_alpha})\")\n",
        "\n",
        "    # Create model\n",
        "    print(\"\\nCreating model...\")\n",
        "    model = create_model(\n",
        "        num_labels=num_labels,\n",
        "        num_hybrid_layers=config['num_hybrid_layers']\n",
        "    )\n",
        "    model = model.cuda()\n",
        "\n",
        "    # Compile for optimization\n",
        "    model = torch.compile(model)\n",
        "\n",
        "    # Enable gradient checkpointing for memory efficiency\n",
        "    supports_gradient_checkpointing = hasattr(model, 'gradient_checkpointing_enable')\n",
        "    if supports_gradient_checkpointing:\n",
        "        model.gradient_checkpointing_enable()\n",
        "        print(\"Gradient checkpointing enabled on model\")\n",
        "    else:\n",
        "        print(\"Model does not support gradient_checkpointing_enable\")\n",
        "\n",
        "    trainable_params, total_params = count_parameters(model)\n",
        "    print(f\"Trainable Parameters: {trainable_params:,}\")\n",
        "    print(f\"Total Parameters: {total_params:,}\")\n",
        "\n",
        "    output_dir = f'./vit-modified-{config_name}-augmented'\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=config['num_epochs'],\n",
        "        per_device_train_batch_size=config['batch_size'],\n",
        "        per_device_eval_batch_size=config['batch_size'],\n",
        "        gradient_accumulation_steps=config['gradient_accumulation_steps'],\n",
        "        learning_rate=config['learning_rate'],\n",
        "        weight_decay=config['weight_decay'],\n",
        "        warmup_ratio=config['warmup_ratio'],\n",
        "        eval_strategy='epoch',\n",
        "        save_strategy='epoch',\n",
        "        logging_strategy='steps',\n",
        "        logging_steps=50,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model='eval_loss',\n",
        "        greater_is_better=False,\n",
        "        save_total_limit=2,\n",
        "        remove_unused_columns=False,\n",
        "        label_names=[\"labels\"],\n",
        "        push_to_hub=False,\n",
        "        report_to='none',\n",
        "        seed=42,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        dataloader_num_workers=2,\n",
        "        dataloader_pin_memory=True,\n",
        "        max_grad_norm=1.0,\n",
        "        gradient_checkpointing=supports_gradient_checkpointing,\n",
        "        eval_accumulation_steps=1,\n",
        "        optim=\"adamw_torch\",\n",
        "        lr_scheduler_type=\"cosine\",\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = AugmentedTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_ds,\n",
        "        eval_dataset=val_ds,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=7)],\n",
        "        aug_config=config['aug_config']\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    print(f\"\\nStarting training...\")\n",
        "    total_steps = len(train_ds) // config['batch_size'] * config['num_epochs']\n",
        "    print(f\"Total training steps: {total_steps}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_result = trainer.train()\n",
        "    training_time = time.time() - start_time\n",
        "\n",
        "    print(f\"\\nTraining completed!\")\n",
        "    print(f\"\\tTraining time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
        "    print(f\"\\tTraining loss: {train_result.metrics.get('train_loss', 0):.4f}\")\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "    # Evaluate\n",
        "    print(f\"\\nEvaluating...\")\n",
        "    eval_metrics = trainer.evaluate()\n",
        "    print(f\"Evaluation completed!\")\n",
        "    print(f\"\\tTest Accuracy: {eval_metrics.get('eval_accuracy', 0):.4f}\")\n",
        "    print(f\"\\tTest Loss: {eval_metrics.get('eval_loss', 0):.4f}\")\n",
        "\n",
        "    clear_memory()\n",
        "\n",
        "    # Detailed evaluation\n",
        "    overall_metrics = evaluate_model_detailed(trainer, val_ds, config_name)\n",
        "    overall_metrics['train_time'] = training_time\n",
        "    overall_metrics['train_loss'] = train_result.metrics.get('train_loss', 0)\n",
        "    overall_metrics['eval_loss'] = eval_metrics.get('eval_loss', 0)\n",
        "    overall_metrics['trainable_params'] = trainable_params\n",
        "    overall_metrics['total_params'] = total_params\n",
        "    overall_metrics['description'] = config['description']\n",
        "\n",
        "    # Plot history\n",
        "    plot_training_history(trainer.state.log_history, config_name)\n",
        "\n",
        "    # Save metrics\n",
        "    overall_metrics_df = pd.DataFrame([overall_metrics])\n",
        "    overall_csv_path = os.path.join(CSV_OUTPUT_DIR, f'{config_name}_overall_metrics.csv')\n",
        "    overall_metrics_df.to_csv(overall_csv_path, index=False)\n",
        "    print(f\"Overall metrics saved to: {overall_csv_path}\")\n",
        "\n",
        "    # Save model\n",
        "    trainer.save_model(output_dir)\n",
        "    processor.save_pretrained(output_dir)\n",
        "    print(f\"\\nModel saved to {output_dir}\")\n",
        "\n",
        "    return overall_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7d144c",
      "metadata": {
        "id": "8c7d144c"
      },
      "source": [
        "## 8. Run Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e9805bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "collapsed": true,
        "id": "4e9805bc",
        "outputId": "8e944dff-e9a1-4844-94ab-496bd603c5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Experiment\n",
            "Experiments: HYBRID_ATTENTION\n",
            "\n",
            "Description: ViT with Local + Global Attention (3 layers, window=3)\n",
            "Learning Rate: 5e-05\n",
            "Batch Size: 64\n",
            "Gradient Accumulation: 1\n",
            "Effective Batch: 64\n",
            "Epochs: 50\n",
            "Weight Decay: 0.05\n",
            "Warmup Ratio: 0.1\n",
            "\n",
            "Augmentation Settings:\n",
            "\tBasic Augmentation: Enabled (flip, rotation, color jitter)\n",
            "\tCutMix: True (prob=0.4, alpha=0.8)\n",
            "\tMixUp: True (prob=0.2, alpha=0.6)\n",
            "\n",
            "Creating model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model does not support gradient_checkpointing_enable\n",
            "Trainable Parameters: 118,293,514\n",
            "Total Parameters: 118,293,514\n",
            "\n",
            "Starting training...\n",
            "Total training steps: 39050\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='783' max='39100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  783/39100 09:10 < 7:29:49, 1.42 it/s, Epoch 1/50]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Precision Macro</th>\n",
              "      <th>Recall Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.828100</td>\n",
              "      <td>0.254338</td>\n",
              "      <td>0.972900</td>\n",
              "      <td>0.972859</td>\n",
              "      <td>0.972859</td>\n",
              "      <td>0.973540</td>\n",
              "      <td>0.972900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Starting Experiment\")\n",
        "\n",
        "\n",
        "clear_memory()\n",
        "\n",
        "try:\n",
        "    results = train_hybrid_attention(EXPERIMENT_CONFIG)\n",
        "    print(\"\\nExperiment completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nError during training: {str(e)}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    clear_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cb52221",
      "metadata": {
        "id": "0cb52221"
      },
      "source": [
        "## 9. Final Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87edf1c3",
      "metadata": {
        "id": "87edf1c3"
      },
      "outputs": [],
      "source": [
        "if 'results' in dir() and results is not None:\n",
        "    print(\"Final results\")\n",
        "\n",
        "\n",
        "    print(f\"\\n{'Metric':<25} {'Value':<15}\")\n",
        "    print(\"-\"*40)\n",
        "    print(f\"{'Accuracy':<25} {results['accuracy']:.4f}\")\n",
        "    print(f\"{'F1-Score (Macro)':<25} {results['f1_macro']:.4f}\")\n",
        "    print(f\"{'F1-Score (Weighted)':<25} {results['f1_weighted']:.4f}\")\n",
        "    print(f\"{'Precision (Macro)':<25} {results['precision_macro']:.4f}\")\n",
        "    print(f\"{'Recall (Macro)':<25} {results['recall_macro']:.4f}\")\n",
        "    print(f\"{'Training Loss':<25} {results['train_loss']:.4f}\")\n",
        "    print(f\"{'Eval Loss':<25} {results['eval_loss']:.4f}\")\n",
        "    print(f\"{'Training Time (min)':<25} {results['train_time']/60:.2f}\")\n",
        "    print(f\"{'Trainable Params (M)':<25} {results['trainable_params']/1e6:.2f}\")\n",
        "\n",
        "    # Save results\n",
        "    with open('hybrid_attention_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "    print(\"\\nResults saved to hybrid_attention_results.json\")\n",
        "else:\n",
        "    print(\"\\nNo results available!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba22574",
      "metadata": {
        "id": "5ba22574"
      },
      "source": [
        "## 10. Download Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac87bab2",
      "metadata": {
        "id": "ac87bab2"
      },
      "outputs": [],
      "source": [
        "# Download all results as a zip file\n",
        "!zip -r results.zip *.png *.json csv_results/ vit-modified-*/\n",
        "\n",
        "from google.colab import files\n",
        "files.download('results.zip')\n",
        "\n",
        "print(\"\\nResults downloaded!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}